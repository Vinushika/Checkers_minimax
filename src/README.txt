We did a variety of things for improving play. First of all, we started with Vinushka's randomized code, since it seemed to work better than Calvin's static evaluation of the board, and Skyler's own randomizer when we played them all against each other.

WARNING: MainClass has been modified! This was done to ensure that the MapDB is saved when the strategy finishes, and so that no conflicts would happen with other groups that may have modified Control.

WARNING 2: The "org" folder is MapDB, and is REQUIRED to run this version!

The main improvements done were:

First of all, Calvin adapted the code to include a negamax version of alpha-beta pruning. This was implementing by taking getBestMove() and having it call negamax(), such that we could still use the recursive version of negamax without having to add extra parameters to either the SearchContext or SearchResult. This sped up almost every single play by a considerable amount (before we added in the adaptable depth code, this sped up games that would take 750ms to about 50 - a tremendous improvement!), without affecting our win rate adversely. After adapting the code to use the variable depth method, the speed increase meant we could take advantage of examining deeper down the tree, and win rate increased for both red and yellow.

Skyler looked at MapDB and was initially very excited. We set up a cache limit of 1,000,000 for the HTreeMap and had it prune old records, as well as save some chunk of the moves to disk for future reading. There are some moves stored on disk, but Skyler will explain these in class because I, the writer of this document, don't quite understand what they are. Because the code at this point had already been shifted to the depth-adapted version, it was hard to judge the effect on runtime. However, we were able to increase the number of random games played to 50 without running out of time, so it seems to have worked in our favor. 

Vinushka at first was only going to implement the weighted probability distribution both for making initial moves (and therefore having a better chance of generating the best alpha and beta on the first branch) and for playing the N random games when we hit the maximum depth (to better represent "best moves" by the two players as opposed to purely random). However, he realized that when we did TicTacToe, adding a random iterator tremendously slowed down the program, and looked up to see whether there was a faster way of generating decent random numbers. As a matter of fact, there is an algorithm developed by George Marsaglia, a mathematician, has a maximal period of 2^128, and is generated in under 10 x86 instructions in C! The entire algorithm is 3 bitshifts - this seemed too good to be true, but there's a lot of incredibly dense statistics that go into why this works. That said, implementing this led to an improvement of 100-200ms for games that took over 1000ms, without affecting our winrate for the non-adaptive-depth version of the code. Adding the weighted probability distribution, on average increased our winrate against the strategy left as it was before the weighting, but sometimes the weighting increases our runtime drastically, possibly because it is generating too many positions that have already been filled, when the two middle columns have been filled. We haven't done enough runtime testing to find out whether this is the case, or whether there is something else going on, but the algorithm only runs out of time on the first move.

Overall, the improvements have led to faster code that can look much deeper in the tree and produce better random results. Hopefully this beats out the other groups!

